---
Company: NileAGI
comments: The first Malty-Purpose Swahili Language Model
title:  "Rafiki Language Model"
Adress: Kigamboni, Dar es Salaam
date:   August, 2023
---

### RAFIKI LANGUAGE MODEL

> The First Ever Malty-Purpose Swahili Language Model


### Content
[Intruduction to Rafiki Language Model](###Intruduction-to-Rafiki-Language-Model)

[Steps Towards Rafiki Language Model](###Steps-Towards-Rafiki-Language-Model)

[Team](###Team)


### Intruduction to Rafiki Language Model

#### Rafiki Language Model
We know that the ML/AI landscape is moving or perhaps it has moved toward the direction of the Large Models, which in recent years they appear to work better than the conventional methods, this might be for a few reasons like huge corpse of data that own by bigger companies and the ones that are in the internet, and off course the discovery of the transformers that uses attention model.

Despite all of the effort that have been done by the big companies to push the bar to make language model work well in languages which have much more datasets in the internet like English Language, this is still not the case for Low resourced Languages like Swahili which is wildly spoken in East Africa and many parts of Africa

The problem with the current Large Language Model is, they miss the touch and the beauty of the Swahili Language and what it can solve to African people at Large in the field of conversational AI, text to text, text to image, image to text, voice to text and text to voice problems.

These applications have vast and wide range of the problem they can solve to a very low-level individuals, small business, farmers, middle income and high-income business and even the governments of many countries in Africa.

**Rafiki Language Model** aim to solve this problem, this is the Multi-Purpose Open-Source Swahili Language model aim to breach the gape in the AI field and African continent at large by providing the state-of-the-Art performance in the problem of Transcribing, Transcription, Translation and Conversational AI. 

It is worth noticing that we Aim for Rafiki Language Model to not be Large Language Model at all, for some reasons:

  a. We believe Safe AGI will running and trained from your laptop at your room and this will not be possible if the model keep continue to grow Larger and Larger, which will make them hard to be accessible with everyone like the internet does, assume what it would be if to access internet you would have to have Nvidia GPU, the internet wouldn’t open all the possibilities it has opened today. Accessibility to as is very important as to AGI.

  b. Opening up new possibilities in African Market and Economy, the current best Language models are owned by the few big tech companies or perhaps there are few that are open sourced now but they still large for a small startup from Africa to run to work with them, but if we make these models to be smaller, we will be able to open up the hall new possibilities for even emerging tech companies to solve different problems in Africa

#### Rafiki Language Model Purpose

To be a multi-purpose but yet small open-source Language model that work on Transcription, Transcribing, Translation and Conversational AI tool/model to go with in Swahili.

#### The Current Problem

No one company is working to make these Language models highly efficient but yet smaller to be used seamlessly and in a decentralized manner, without forgetting the issue of censorship over the available models. 

#### NileAGI Mission

Our Mission is quite simple, “Solving Intelligence towards Artificial Intelligence, making sense of AI for all”, which is more resonate with our purpose with Rafiki Language Model.
We believe AGI someday will be trained in a laptop while drinking coffee on your bed.
But all of this will start with Rafiki Language Model.

### Steps Toward Rafiki Language Model

#### First Phase

  •	Collecting Text Conversational Language Data (This is perhaps the continuous process)
    •	In every 1 month (the first review is at 08/09/2023) will do review on where we are in data collection
  •	Cleaning data
    •	This goes hand to hand with collecting the data (This will be reviewed every time we review the collection of data)
  •	Developing Tokenizer
    •	In 1 month (the first review is at 08/09/2023) will do review on where we are.
    •	This also must continue at the same time as collecting data and improving it as when we get new data.
  •	Creating Initial text conversational model
    •	In 2 months (the first review is at 08/10/2023) will do review on where we are
> NOTE: Let’s point out that collection of data is quote challenges.
        •	We have the obligation to come up with the effective ways of how we can collect useful data to use in our model
